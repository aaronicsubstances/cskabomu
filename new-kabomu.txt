Email to Awudu
1. Kabomu Library is a message passing framework for building networking protocols for distributed systems
2. A message is just a stream of bytes which is usually assumed to be bounded. Kabomu seeks to support frameworks which already support for exchanging bounded messages, by implementing support for exchanging unbounded messages as well.
3. All protocols based on the framework support both explicitly acked one-way request (for the purpose of data transfer), and implicitly acked request-response message exchange patterns.
4. Some protocols work with immediate processing while others work with deferred processing
5. Protocols which employ immediate processing are "semantically compatible" with HTTP/1.0, so that terminology of request methods, response status codes, headers and bodies apply. They differ only in their underlying transports, which are not limited to TCP.
6. Protocols which employ deferred processing are "semantically compatible" with a subset of JMAP Mail. They differ only in their underlying transports, which are limited to HTTP. Deferred processing will be done by automated email thread processors. 
7. Since webmail makes it possible to send email via http, point 6 can still be seen from the alternative perspective of http. This will require use of "dictionary of callbacks" idea for simulating deferred processing as immediate processing (callbacks are invoked with error of "not done yet" after some timeout to signal that request is really being processed in a deferred manner).
8. From playing around with RINA research, my opinion is that it is not useful to have long lived connections or flows which have to tolerate idleness or even restarts of peers. Rather I propose we settle for bounded message exchanges, and unbounded message exchanges which neither tolerate idleness nor restarts of peers. Thus I had to drop a lot of RINA's concepts, and instead continue to emulate success of HTTP's stateless request-response model.
-----------------------------

# Quasi Procedure Call (QPC) Services for Kabomu


## Requirements

These are the challenges which all QPC services of Kabomu must address in order to send requests and receive replies similar to making local procedure calls. This challenges arise because communication/transportation can go beyond a single host (computer). Hence they are not present in making local procedure calls.

1. A request or response may be lost or destroyed in the network (e.g. due to a network disconnection), and hence will never reach its intended destination.
2. A request or response may experience significant delays during its transmission, so that the usual style of blocking for responses during local procedure call may be too costly. This suggests that QPC services 
    1. use non-blocking style (e.g. through callbacks) to lower cost of such delays on computing resources of the sender.
    2. optionally support cancellation.
3. Networks can hold on to requests for significantly long times, even after sender has given up on it. This suggests that even if a sender is no longer interested in a transmission, a QPC service may have to hold on to it for some time before abandoning it as well.
4. The network can outlive restarts of senders and receivers. This means that transmissions before restarts can interfere with those created afterwards, and suggests that a QPC service may have to slow down after restart,  before processing requests at full capacity.
3. A request or response may be duplicated in the network, so that the intended destination sees it more than once. This combined with the previous two points (delays and outliving restarts) is the challenge of **duplication protection**, which is the greatest challenge of all. *Providing duplication protection solves almost all of the challenges of quasi procedure calls.* In fact, QPC services of Kabomu differ mostly in their solution to this problem.
4. Upgrading QPC service doesn't automatically result in both ends of communication using it. It is possible that only one end uses the latest version, and hence upgrades must be carefully done to be backward compatible.
4. A request or response may be larger than what a network is capable of transmitting at once, or larger than what the receiving end is capable of processing at once. This implies that some requests must be chopped into sizable pieces at the sender for transmission. Correspondingly, on delivery such chopped-up pieces must be combined into one for the receiver so that the receiver just gets a single message in the end.
5. Requests may fill up a receiver's buffers faster than the receiver can handle. A way (known as flow control) must be found to slow down "fast" senders.
5. Requests and responses may fill up network's buffers faster than network can handle. This is the problem of network congestion. A way (known as congestion control) must be found to detect congestion, and slow down senders and receivers using flow control.
5. A request or response may be modified accidentally or maliciously by the network before reaching its intended destination, so that destination gets a corrupted or wrong message. This suggests the need for some cross checks on received messages, or some more comprehensive security measures.
6. When data transfers are to be sent sequentially, the use of sending the data chunks one by one during local procedure calls (known as stop-and-wait), is inefficient for networking across computers because it underutilises the expensive network capacity. For proper utilisation of network capacity, data chunks must be sent in batches. Since each chunk in a batch may be delayed differently from others (or worse dropped), they may arrive out of order, and that brings up the need for ensuring ordered delivery of chunks during sequential data transfers.

The deployment environments of Kabomu are the on Internet via TCP/TLS and within the same computing host via IPC mechanisms. What Kabomu seeks to do is to emulate some of TCP's design to create few protocols which support lower layers other than IP, for the sake of
   1. leveraging the greater efficiency made possible by intrahost communications. In other words, use of TCP on localhost is not necessary when faster and more memory efficient alternatives exist by not needing slow starts and time wait states.
   2. simplifying network programming by tolerating idleness and restarts of connection endpoints better than TCP.

Actually TCP/TLS and almost all the IPC mechanisms address all of the QPC challenges directly. Kabomu's design goal is to leverage their convenient features for simplicity in its protocols. For example Kabomu doesn't handle security and congestion control because TCP/TLS and IPC mechanisms already cater for that.

Kabomu also leverages TCP's windowed transfer to great effect through multiplexing, by using the simplest flow control method which is stop-and-wait.

The most important benefit of TCP and IPC mechanisms for Kabomu is their ability to transmit large payloads (ie far larger than 512 of DNS via UDP or 1500 of Ethernet).

To prevent clients from having to deal with uncertainty about the safest minimum payload size to use, Kabomu offers clients a minimum value of **30KB**. Thus all underlying QPC services which may be used by Kabomu QPC services, *can send messages of up to 30KB in size*. 30KB is enough to carry typical requests and responses of quasi procedure calls. Beyond this limit, clients may have to fragment and reassemble payloads on their own.

The QPC services for Kabomu leverage this benefit of large payloads, to employ 30 bytes worth of transmission overhead, since such overhead will be a small fraction of payloads. A major complexity of TCP's design comes from finite sequence numbers of 16 bits (can go up by 14 bits through extensions) and dealing with sequence number wraparound. Several features of TCP such as time wait state, quiet time state, ISN selection, PAWS, etc. exist because of this. Kabomu uses alternative strategy of uuids and timestammped variable length integers which do not involve sequence numbers wrapping around, but at the small cost of slightly larger payloads.
    
   1. uuids are random 16 byte sequences.
   2. timestamp is unsigned 16-bit unix epoch integer in seconds, modulo 43200. That is, the number of seconds since 12:00 am or 12:00 pm UTC, whichever is closer.
       1. In simple terms this is equivalent to UTC time in 12-hour format, without the AM or PM, and with hour value of 12 equivalent to 0.
       1. To compare two timestamps A and B, the current timestamp is needed. Given current timestamp C, compare negative ((C - A) mod 43200) and negative ((C - B) mod 43200).
       2. The interpretation of the negative quantities being compared is number of seconds ago relative to current timestamp.
       3. E.g. If the current time is 12:00 PM (0), then comparing 10:00 AM (36000) to 2:00 PM (7200) boils down to comparing -7200 with -36000. Since -7200 is bigger, that shows 10:00 AM is "more recent" than 2:00 PM, and hence 2:00 PM was intepreted as belonging to the previous 12-hour cycle, ie as 2:00 AM.
       3. On the other hand if the current time is 6:00 PM (21600), then comparing 10:00 PM (36000) to 2:00 PM (7200) boils down to comparing -28800 with -14400. Since -14400 is bigger, that shows 2:00 PM is "more recent" than 10:00 PM, and hence 10:00 PM was interpreted as belonging to the previous 12-hour cycle, ie as 10:00 AM.
       1. This takes advantage of the fact that the maximum packet lifetimes of physical computer networks in the real world is far less than 1 hour, and hence far far less than 12 hours. 
       2. Thus the ambiguity of AM or PM is definitely not a problem, and was done so that 43,200 can fit into a unsigned 16-bit integer. 86,400 would have required more bits. Similarly, seconds was chosen over milliseconds since 43,200,000 would have required even more bits.
   3. variable length integer is a sequence of bytes of length >= 1 representing some big-endian unsigned integer, where the first few bytes indicates the variable length in bytes.
       1. the bytes indicating the variable length form a sequence of zero or more 7-bit integer parts with leading bit of 1, followed by a terminating 7-bit integer part with leading bit of 0.
       2. The concatenation of the 7-bit integer parts in big endian, excluding the leading bits, gives the unsigned variable length value.
   4. timestampped variable length integer is a combination of timestamp and variable length integer for use as a replacement for sequence numbers which do not wrap around.


## QPC101 (SunRPC Strategy)

1. Assume qpc101 will be used for requests for which duplication isn't a problem for clients (of qpc101). In other words, qpc101 doesn't provide duplication protection on its own at all.

2. reset and exception handling.

3. async forward_send_request with callback and cancellation involving reset (ie even if forward_send_request returns, cancellation_handle usage ensures reset holds).

4. begin_receive which deals with send requests with new pdu field pdu type (with values "req" and "resp"); and additional process_send_request abstract method which takes a byte queue and a callback. Callback takes exception and byte queue as response.

5. multiplexing with new pdu fields: version (1 byte) and transaction id (4 bytes, internal) and new param for begin_send() et al: remote_address which is an instance of class transferendpoint.

    1. Do not store any state at receiver but rather pass to process_send_request and receive in callback. 
    2. Add random_generator property which can be changed to generate predictable sequence for testing. 
    3. Property should belong to a new class. Call it RandomGenerator abstract class with abstract methods: next_4byte_int, and next_uuid
    4. Using transaction ids of size 4 bytes is not a problem since we check and ensure it is not being used for another send request.

6. Deal with challenge of message size limit, by adding "max pdu size" option and rejecting oversized messages. Not so straightforward as overhead of pdu fields required for communication must be accounted for.

7. Deal with challenge of no connectivity, by adding "send timeout" option, and introduce event loop. Apply timeout at sending end, and introduce dictionary state keyed by request id and remote address.

9. Deal with challenge of intermittent delays by implementing auto retries using "min/max backoff" options.

10. Add and implement option "max retry count". Max retry count works differently from previous thinking by simply counting retries and disabling them on reaching max limit. - *make an internal implementation detail*.

11. Implement cancellation of retries, by letting begin_send and forward_send_request take cancellation handles.

## QPC102A (TCP+LargeISN Strategy)

1. Create package qpc102 with same API as those above. It is designed to solve the challenge of duplication, by employing TCP's connection phase and doing away with the slow start and time-wait state through use of guids as ISNs. This solution comes at the cost of two round trips instead of one, and hence qpc102A is the slowest of all.

2. Have qpc101-based equivalent API for creating uuid/guid for request id. If guid exists for that request id just return it as is, and slide ejection timeout. Have at receiver's end: dictionary of request id and remote address to a structure with guid and timeout properties.  Use pdu types "req_trans" and "resp_trans".

3. Have another qpc101-based equivalent API for using guid to perform operation without delays. Have at receiver's end: dictionary of guid to struct of request id, processed flag, processed result, processed error code. Impose unacked time option on processing.

4. Lastly have at sender's end: list of requests to send, with their timeouts. Initially timeouts are sliding. Upon processed, change to "dally_state_period" in absolute timeout in dally state. if guid was not used, clear immediately. 

5. Also add another qpc101-based equivalent API, but without caring about the response, for clearing receiver's dictionary entries before their timeout with guid. Use pdu type "fin".

6. Implement auto retries and the rest of the remaining steps as listed in qpc101  (can make use of some of the code from the csharp message transfer manager implementation).

## QPC102B (TCP+Timestamp Strategy)

1. Extend package qpc102 to solve the challenge of duplication, by employing TCP's slow start and timestamp option, and skipping the connection phase, in order to be able to have best case of using 1 round trip instead of 2. This is done by using timestampped variable length integers as sequence numbers, and so avoid all issues to do with possibility of wrap around and reuse of sequence numbers.

1. Add "time_precision" and MPL options, and use them to reject pdus which are too old.

2. Add option for receiver slow start period, which should be less than MPL (or even 0). If for some reason, one is fine with permanently using handshake mode, then can set this option to infinity.

2. To enable parallel processing of qpc requests, interpret the first 2 bytes of a sequence number as its group number.

3. To avoid need for sequence numbering lockstep between sender and receiver, let receiver accept any sequence number from sender after exiting handshake required mode, and then from that time onwards, as long as it is larger than what was last received within its group.

4. Add special error code "handshake required". Senders must always in start in handshake mode by using qpc102a. Sender must also detect when receiver is in handshake required mode, and use qpc102a instead.

5. Add ack flag for "handshake required", which receiver must use in its qpc102a responses to inform sender of when the latter can switch to qpc102b.

6.  Max variable length supported by receivers should be at least 8. And so a sender should be prepared to switch to qpc102a if variable length is about to exceed 8 and its receiver doesn't support variable lengths beyond 8.

7. qpc102a can be used even if handshake is not required. In fact senders can choose in the case of 8 byte exhaustion of varible length sequence numbers, to switch permanently to qpc102a since that will mean that network is so fast that qpc102a will not be considered to be slow anymore.

7. Even in qpc102b we will still need dally states and fins, which work just like in qpc102a.

------------
remaining
---------

default source and sinks
------------------------
-add a sink which embeds a source, and a soure which embeds a sink
-leave it to another library to provide sources and sinks backed by async streams, which will likely need 3rd party libs like Netty, Vert.x, Twisted and ReactPHP.

quasi http
----------
keep csv utils for quasi http? so we don't have a dependency on some library.

deferred processing
-------------------
default cache
-major advantage over existing caches is ttl, postpone timeout operation, and eviction handler notification for ttl et al
-use async methods throughout? complicates operations like containsKey (delegate to get), size, isEmpty (delegate to size).
-could support sync operations by leaving keys whose ttl have expired intact, 
 and only clear them when max is reached.
-can add min sweep time option for cleaning expired ttls
-only allow ttl in addasync case
-call eviction if ttl elapses or user himself clears or max is reached.
-could use atomic increment and decrement for size and isEmpty.
-containsKey and get are not read only and so can be async.
-assume eventloop and single threaded
-set insert time
-update last acess time, and frequency of get usage.
-on max count reached, perform linear search to evict "least" item based on current policy
-policies are MRU, LRU, FIFO, LFU (setmru,ismru, etc)
-setting of policy can also use atomic compare and swap
-alternatively ignore compare and swap, and have an interface that client can lock with throughout synchronized subclass. like java's collection.synchronizedlist(list)
